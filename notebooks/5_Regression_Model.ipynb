{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "154a788f-4def-44a3-9833-a3b4998ebefc",
   "metadata": {},
   "source": [
    "# 5. Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99f28d8-8a54-475c-99c3-cd9c66354f00",
   "metadata": {},
   "source": [
    "### Cell 1 — Overview, imports, global config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2ce52f5-c044-4169-b3bf-a03352e5c9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "REGRESSION MODEL EVALUATION – FINAL EXPERIMENT PIPELINE\n",
      "======================================================================\n",
      "\n",
      "Experiment configuration:\n",
      "Horizons: [1, 6, 12, 24]\n",
      "FE types: ['hourly', 'daily', 'merge']\n",
      "Data versions: ['orig', 'cleaned']\n",
      "Results dir: ../results_reg\n",
      "Run tag: 20251119_020758\n",
      "\n",
      "[STEP 0] Loading base data for target construction...\n",
      "base_df shape: (8833, 12)\n",
      "base_df range: 2004-03-10 18:00:00 → 2005-04-04 14:00:00\n",
      "Years present: [2004, 2005]\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# Cell 1: Imports & global configuration\n",
    "# ================================================================\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Optional XGBoost; if not available, fall back to GradientBoosting\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "    HAS_XGB = True\n",
    "except Exception:\n",
    "    HAS_XGB = False\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"REGRESSION MODEL EVALUATION – FINAL EXPERIMENT PIPELINE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ---------------- Paths & configuration ----------------\n",
    "PROJECT_ROOT = Path(\"..\")\n",
    "\n",
    "PREP_DIR = PROJECT_ROOT / \"output_Preprocessing_TemporalDataSplitting\"\n",
    "FE_DIR   = PROJECT_ROOT / \"output_FeatureEngineering\"\n",
    "\n",
    "FE_TRAIN_ORIG_DIR  = FE_DIR / \"train\" / \"orig\"\n",
    "FE_TRAIN_CLEAN_DIR = FE_DIR / \"train\" / \"cleaned\"\n",
    "FE_TEST_DIR        = FE_DIR / \"test\"\n",
    "\n",
    "RESULTS_DIR  = PROJECT_ROOT / \"results_reg\"\n",
    "FIG_DIR      = RESULTS_DIR / \"figs\"\n",
    "ANALYSIS_DIR = RESULTS_DIR / \"analysis\"\n",
    "\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "ANALYSIS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Horizons and feature types follow the classification setup\n",
    "HORIZONS   = [1, 6, 12, 24]\n",
    "FE_TYPES   = [\"hourly\", \"daily\", \"merge\"]\n",
    "DATA_VERS  = [\"orig\", \"cleaned\"]\n",
    "\n",
    "# We focus on four pollutants (NMHC was dropped in preprocessing)\n",
    "POLLUTANTS = [\"CO(GT)\", \"C6H6(GT)\", \"NOx(GT)\", \"NO2(GT)\"]\n",
    "\n",
    "RUN_TAG = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "print(\"\\nExperiment configuration:\")\n",
    "print(f\"Horizons: {HORIZONS}\")\n",
    "print(f\"FE types: {FE_TYPES}\")\n",
    "print(f\"Data versions: {DATA_VERS}\")\n",
    "print(f\"Results dir: {RESULTS_DIR}\")\n",
    "print(f\"Run tag: {RUN_TAG}\")\n",
    "\n",
    "# ---------------- Load base data for targets ----------------\n",
    "print(\"\\n[STEP 0] Loading base data for target construction...\")\n",
    "\n",
    "base_df = pd.read_csv(\n",
    "    PREP_DIR / \"preprocessed_data.csv\",\n",
    "    index_col=\"DateTime\",\n",
    "    parse_dates=True,\n",
    ")\n",
    "base_df = base_df.sort_index()\n",
    "\n",
    "missing_pollutants = [p for p in POLLUTANTS if p not in base_df.columns]\n",
    "if missing_pollutants:\n",
    "    raise KeyError(f\"Missing pollutant columns in base_df: {missing_pollutants}\")\n",
    "\n",
    "print(f\"base_df shape: {base_df.shape}\")\n",
    "print(f\"base_df range: {base_df.index.min()} → {base_df.index.max()}\")\n",
    "print(f\"Years present: {sorted(base_df.index.year.unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461abd9f-9ca0-4591-9910-2b724b27f0ff",
   "metadata": {},
   "source": [
    "### Cell 2 — Helpers: loading data, labels, models, confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "060caa07-90b2-4a06-bb68-03fdeeb2a3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Cell 2: Helper functions (targets, loaders, models, metrics, plots)\n",
    "# ================================================================\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# ---------------- Target construction ----------------\n",
    "def make_future_reg_target(df: pd.DataFrame, pollutant: str, h: int) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Build y_{t+h} for a given pollutant and horizon h.\n",
    "    \"\"\"\n",
    "    if pollutant not in df.columns:\n",
    "        raise KeyError(f\"{pollutant} not found in base_df\")\n",
    "    y_future = df[pollutant].shift(-h)\n",
    "    y_future = y_future.dropna()\n",
    "    return y_future\n",
    "\n",
    "\n",
    "# ---------------- Feature loaders ----------------\n",
    "def load_train_test_fe(fe_type: str, data_ver: str):\n",
    "    \"\"\"\n",
    "    Load 2004 train and 2005 test feature tables for a given\n",
    "    feature type (hourly / daily / merge) and data version.\n",
    "    \"\"\"\n",
    "    if fe_type not in FE_TYPES:\n",
    "        raise ValueError(f\"Unknown FE type: {fe_type}\")\n",
    "\n",
    "    if data_ver == \"orig\":\n",
    "        train_path = FE_TRAIN_ORIG_DIR / f\"train_2004_fe_{fe_type}_orig.csv\"\n",
    "    elif data_ver == \"cleaned\":\n",
    "        train_path = FE_TRAIN_CLEAN_DIR / f\"train_2004_fe_{fe_type}_cleaned.csv\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown data version: {data_ver}\")\n",
    "\n",
    "    test_path = FE_TEST_DIR / f\"test_2005_fe_{fe_type}.csv\"\n",
    "\n",
    "    if not train_path.exists():\n",
    "        raise FileNotFoundError(f\"Train FE file not found: {train_path}\")\n",
    "    if not test_path.exists():\n",
    "        raise FileNotFoundError(f\"Test FE file not found: {test_path}\")\n",
    "\n",
    "    X_tr = pd.read_csv(train_path, index_col=\"DateTime\", parse_dates=True)\n",
    "    X_te = pd.read_csv(test_path, index_col=\"DateTime\", parse_dates=True)\n",
    "\n",
    "    X_tr = X_tr.sort_index()\n",
    "    X_te = X_te.sort_index()\n",
    "\n",
    "    return X_tr, X_te\n",
    "\n",
    "\n",
    "def build_train_test_for_fe(fe_type: str, data_ver: str, pollutant: str, h: int):\n",
    "    \"\"\"\n",
    "    For a given FE type + data version + pollutant + horizon,\n",
    "    build aligned (X_train, y_train, X_test, y_test) with\n",
    "    time-respecting splits.\n",
    "    \"\"\"\n",
    "    X_tr, X_te = load_train_test_fe(fe_type, data_ver)\n",
    "    y_full = make_future_reg_target(base_df, pollutant, h)\n",
    "\n",
    "    # Train: 2004 only, and avoid labels that would use 2005\n",
    "    idx_tr = X_tr.index.intersection(y_full.index)\n",
    "    boundary = pd.Timestamp(\"2004-12-31 23:00:00\") - pd.Timedelta(hours=h - 1)\n",
    "    idx_tr = idx_tr[idx_tr <= boundary]\n",
    "    X_train = X_tr.loc[idx_tr]\n",
    "    y_train = y_full.loc[idx_tr]\n",
    "\n",
    "    # Test: 2005 only\n",
    "    idx_te = X_te.index.intersection(y_full.index)\n",
    "    X_test = X_te.loc[idx_te]\n",
    "    y_test = y_full.loc[idx_te]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "# ---------------- Model zoo ----------------\n",
    "def model_zoo_reg():\n",
    "    \"\"\"\n",
    "    Regression models:\n",
    "      - Linear Regression\n",
    "      - Random Forest Regressor\n",
    "      - XGBoost Regressor (or GradientBoostingRegressor as fallback)\n",
    "    \"\"\"\n",
    "    models = {}\n",
    "\n",
    "    models[\"LinReg\"] = LinearRegression()\n",
    "\n",
    "    models[\"RF\"] = RandomForestRegressor(\n",
    "        n_estimators=400,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    if HAS_XGB:\n",
    "        models[\"XGB\"] = XGBRegressor(\n",
    "            n_estimators=400,\n",
    "            max_depth=5,\n",
    "            learning_rate=0.05,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            objective=\"reg:squarederror\",\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "        )\n",
    "    else:\n",
    "        models[\"GB\"] = GradientBoostingRegressor(\n",
    "            n_estimators=300,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=3,\n",
    "            random_state=42,\n",
    "        )\n",
    "\n",
    "    return models\n",
    "\n",
    "\n",
    "# ---------------- Metrics ----------------\n",
    "def eval_reg_metrics(y_true, y_pred) -> dict:\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae  = mean_absolute_error(y_true, y_pred)\n",
    "    r2   = r2_score(y_true, y_pred)\n",
    "    return {\"RMSE\": rmse, \"MAE\": mae, \"R2\": r2}\n",
    "\n",
    "\n",
    "# ---------------- Simple residual / time-series plots ----------------\n",
    "def save_ts_residual_plots(\n",
    "    y_true: pd.Series,\n",
    "    y_pred: np.ndarray,\n",
    "    title_prefix: str,\n",
    "    out_dir: Path,\n",
    "    sample_n: int = 500,\n",
    "):\n",
    "    \"\"\"\n",
    "    Save two small figures:\n",
    "      1) observed vs predicted over time (first sample_n points)\n",
    "      2) residuals over time (same window)\n",
    "    \"\"\"\n",
    "    if len(y_true) == 0:\n",
    "        return\n",
    "\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    y_true = y_true.sort_index()\n",
    "    y_pred_series = pd.Series(y_pred, index=y_true.index)\n",
    "    residuals = y_true - y_pred_series\n",
    "\n",
    "    sample_true = y_true.iloc[:sample_n]\n",
    "    sample_pred = y_pred_series.iloc[:sample_n]\n",
    "    sample_res  = residuals.iloc[:sample_n]\n",
    "\n",
    "    # Observed vs predicted\n",
    "    plt.figure(figsize=(7, 3))\n",
    "    plt.plot(sample_true.index, sample_true.values, label=\"Observed\", linewidth=1.0)\n",
    "    plt.plot(sample_pred.index, sample_pred.values, label=\"Predicted\", linewidth=1.0)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Concentration\")\n",
    "    plt.title(f\"{title_prefix} – observed vs predicted\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_dir / f\"{title_prefix}_ts.png\", dpi=220)\n",
    "    plt.close()\n",
    "\n",
    "    # Residuals\n",
    "    plt.figure(figsize=(7, 3))\n",
    "    plt.plot(sample_res.index, sample_res.values, linewidth=1.0)\n",
    "    plt.axhline(0.0, color=\"black\", linewidth=0.8)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Residual\")\n",
    "    plt.title(f\"{title_prefix} – residuals\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_dir / f\"{title_prefix}_residuals.png\", dpi=220)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f27900-a1ae-4549-8ed8-e59209f5228d",
   "metadata": {},
   "source": [
    "### Cell 3 — Run full experiment grid, save summary_full_run_*.csv + confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71fc4c14-a634-477a-aefb-c5d8449e7894",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STEP 1] Running regression experiment grid...\n",
      "\n",
      "[Naive] pollutant=CO(GT), h=1\n",
      "\n",
      "[Naive] pollutant=CO(GT), h=6\n",
      "\n",
      "[Naive] pollutant=CO(GT), h=12\n",
      "\n",
      "[Naive] pollutant=CO(GT), h=24\n",
      "\n",
      "[Naive] pollutant=C6H6(GT), h=1\n",
      "\n",
      "[Naive] pollutant=C6H6(GT), h=6\n",
      "\n",
      "[Naive] pollutant=C6H6(GT), h=12\n",
      "\n",
      "[Naive] pollutant=C6H6(GT), h=24\n",
      "\n",
      "[Naive] pollutant=NOx(GT), h=1\n",
      "\n",
      "[Naive] pollutant=NOx(GT), h=6\n",
      "\n",
      "[Naive] pollutant=NOx(GT), h=12\n",
      "\n",
      "[Naive] pollutant=NOx(GT), h=24\n",
      "\n",
      "[Naive] pollutant=NO2(GT), h=1\n",
      "\n",
      "[Naive] pollutant=NO2(GT), h=6\n",
      "\n",
      "[Naive] pollutant=NO2(GT), h=12\n",
      "\n",
      "[Naive] pollutant=NO2(GT), h=24\n",
      "\n",
      "============================================================\n",
      "[GRID] pollutant=CO(GT)  h=1\n",
      "============================================================\n",
      "FE=hourly | data=orig   \n",
      "Train size=6590, Test size=2230, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=hourly | data=cleaned\n",
      "Train size=6414, Test size=2230, Removed by cleaning=176\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=daily  | data=orig   \n",
      "Train size=252, Test size=93, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=daily  | data=cleaned\n",
      "Train size=252, Test size=93, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=merge  | data=orig   \n",
      "Train size=6006, Test size=2230, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=merge  | data=cleaned\n",
      "Train size=5845, Test size=2230, Removed by cleaning=161\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "\n",
      "============================================================\n",
      "[GRID] pollutant=CO(GT)  h=6\n",
      "============================================================\n",
      "FE=hourly | data=orig   \n",
      "Train size=6585, Test size=2225, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=hourly | data=cleaned\n",
      "Train size=6409, Test size=2225, Removed by cleaning=176\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=daily  | data=orig   \n",
      "Train size=252, Test size=93, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=daily  | data=cleaned\n",
      "Train size=252, Test size=93, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=merge  | data=orig   \n",
      "Train size=6001, Test size=2225, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=merge  | data=cleaned\n",
      "Train size=5840, Test size=2225, Removed by cleaning=161\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "\n",
      "============================================================\n",
      "[GRID] pollutant=CO(GT)  h=12\n",
      "============================================================\n",
      "FE=hourly | data=orig   \n",
      "Train size=6585, Test size=2219, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=hourly | data=cleaned\n",
      "Train size=6409, Test size=2219, Removed by cleaning=176\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=daily  | data=orig   \n",
      "Train size=252, Test size=93, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=daily  | data=cleaned\n",
      "Train size=252, Test size=93, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=merge  | data=orig   \n",
      "Train size=6001, Test size=2219, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=merge  | data=cleaned\n",
      "Train size=5840, Test size=2219, Removed by cleaning=161\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "\n",
      "============================================================\n",
      "[GRID] pollutant=CO(GT)  h=24\n",
      "============================================================\n",
      "FE=hourly | data=orig   \n",
      "Train size=6585, Test size=2207, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=hourly | data=cleaned\n",
      "Train size=6409, Test size=2207, Removed by cleaning=176\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=daily  | data=orig   \n",
      "Train size=252, Test size=92, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=daily  | data=cleaned\n",
      "Train size=252, Test size=92, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=merge  | data=orig   \n",
      "Train size=6001, Test size=2207, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=merge  | data=cleaned\n",
      "Train size=5840, Test size=2207, Removed by cleaning=161\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "\n",
      "============================================================\n",
      "[GRID] pollutant=C6H6(GT)  h=1\n",
      "============================================================\n",
      "FE=hourly | data=orig   \n",
      "Train size=6590, Test size=2230, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=hourly | data=cleaned\n",
      "Train size=6414, Test size=2230, Removed by cleaning=176\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=daily  | data=orig   \n",
      "Train size=252, Test size=93, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=daily  | data=cleaned\n",
      "Train size=252, Test size=93, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=merge  | data=orig   \n",
      "Train size=6006, Test size=2230, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=merge  | data=cleaned\n",
      "Train size=5845, Test size=2230, Removed by cleaning=161\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "\n",
      "============================================================\n",
      "[GRID] pollutant=C6H6(GT)  h=6\n",
      "============================================================\n",
      "FE=hourly | data=orig   \n",
      "Train size=6585, Test size=2225, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=hourly | data=cleaned\n",
      "Train size=6409, Test size=2225, Removed by cleaning=176\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=daily  | data=orig   \n",
      "Train size=252, Test size=93, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=daily  | data=cleaned\n",
      "Train size=252, Test size=93, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=merge  | data=orig   \n",
      "Train size=6001, Test size=2225, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=merge  | data=cleaned\n",
      "Train size=5840, Test size=2225, Removed by cleaning=161\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "\n",
      "============================================================\n",
      "[GRID] pollutant=C6H6(GT)  h=12\n",
      "============================================================\n",
      "FE=hourly | data=orig   \n",
      "Train size=6585, Test size=2219, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=hourly | data=cleaned\n",
      "Train size=6409, Test size=2219, Removed by cleaning=176\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=daily  | data=orig   \n",
      "Train size=252, Test size=93, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=daily  | data=cleaned\n",
      "Train size=252, Test size=93, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=merge  | data=orig   \n",
      "Train size=6001, Test size=2219, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=merge  | data=cleaned\n",
      "Train size=5840, Test size=2219, Removed by cleaning=161\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "\n",
      "============================================================\n",
      "[GRID] pollutant=C6H6(GT)  h=24\n",
      "============================================================\n",
      "FE=hourly | data=orig   \n",
      "Train size=6585, Test size=2207, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=hourly | data=cleaned\n",
      "Train size=6409, Test size=2207, Removed by cleaning=176\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=daily  | data=orig   \n",
      "Train size=252, Test size=92, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=daily  | data=cleaned\n",
      "Train size=252, Test size=92, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=merge  | data=orig   \n",
      "Train size=6001, Test size=2207, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=merge  | data=cleaned\n",
      "Train size=5840, Test size=2207, Removed by cleaning=161\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "\n",
      "============================================================\n",
      "[GRID] pollutant=NOx(GT)  h=1\n",
      "============================================================\n",
      "FE=hourly | data=orig   \n",
      "Train size=6590, Test size=2230, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=hourly | data=cleaned\n",
      "Train size=6414, Test size=2230, Removed by cleaning=176\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=daily  | data=orig   \n",
      "Train size=252, Test size=93, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=daily  | data=cleaned\n",
      "Train size=252, Test size=93, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=merge  | data=orig   \n",
      "Train size=6006, Test size=2230, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=merge  | data=cleaned\n",
      "Train size=5845, Test size=2230, Removed by cleaning=161\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "\n",
      "============================================================\n",
      "[GRID] pollutant=NOx(GT)  h=6\n",
      "============================================================\n",
      "FE=hourly | data=orig   \n",
      "Train size=6585, Test size=2225, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=hourly | data=cleaned\n",
      "Train size=6409, Test size=2225, Removed by cleaning=176\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=daily  | data=orig   \n",
      "Train size=252, Test size=93, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=daily  | data=cleaned\n",
      "Train size=252, Test size=93, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=merge  | data=orig   \n",
      "Train size=6001, Test size=2225, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=merge  | data=cleaned\n",
      "Train size=5840, Test size=2225, Removed by cleaning=161\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "\n",
      "============================================================\n",
      "[GRID] pollutant=NOx(GT)  h=12\n",
      "============================================================\n",
      "FE=hourly | data=orig   \n",
      "Train size=6585, Test size=2219, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=hourly | data=cleaned\n",
      "Train size=6409, Test size=2219, Removed by cleaning=176\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=daily  | data=orig   \n",
      "Train size=252, Test size=93, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=daily  | data=cleaned\n",
      "Train size=252, Test size=93, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=merge  | data=orig   \n",
      "Train size=6001, Test size=2219, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=merge  | data=cleaned\n",
      "Train size=5840, Test size=2219, Removed by cleaning=161\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "\n",
      "============================================================\n",
      "[GRID] pollutant=NOx(GT)  h=24\n",
      "============================================================\n",
      "FE=hourly | data=orig   \n",
      "Train size=6585, Test size=2207, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=hourly | data=cleaned\n",
      "Train size=6409, Test size=2207, Removed by cleaning=176\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=daily  | data=orig   \n",
      "Train size=252, Test size=92, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=daily  | data=cleaned\n",
      "Train size=252, Test size=92, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=merge  | data=orig   \n",
      "Train size=6001, Test size=2207, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=merge  | data=cleaned\n",
      "Train size=5840, Test size=2207, Removed by cleaning=161\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "\n",
      "============================================================\n",
      "[GRID] pollutant=NO2(GT)  h=1\n",
      "============================================================\n",
      "FE=hourly | data=orig   \n",
      "Train size=6590, Test size=2230, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=hourly | data=cleaned\n",
      "Train size=6414, Test size=2230, Removed by cleaning=176\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=daily  | data=orig   \n",
      "Train size=252, Test size=93, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=daily  | data=cleaned\n",
      "Train size=252, Test size=93, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=merge  | data=orig   \n",
      "Train size=6006, Test size=2230, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=merge  | data=cleaned\n",
      "Train size=5845, Test size=2230, Removed by cleaning=161\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "\n",
      "============================================================\n",
      "[GRID] pollutant=NO2(GT)  h=6\n",
      "============================================================\n",
      "FE=hourly | data=orig   \n",
      "Train size=6585, Test size=2225, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=hourly | data=cleaned\n",
      "Train size=6409, Test size=2225, Removed by cleaning=176\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=daily  | data=orig   \n",
      "Train size=252, Test size=93, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=daily  | data=cleaned\n",
      "Train size=252, Test size=93, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=merge  | data=orig   \n",
      "Train size=6001, Test size=2225, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=merge  | data=cleaned\n",
      "Train size=5840, Test size=2225, Removed by cleaning=161\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "\n",
      "============================================================\n",
      "[GRID] pollutant=NO2(GT)  h=12\n",
      "============================================================\n",
      "FE=hourly | data=orig   \n",
      "Train size=6585, Test size=2219, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=hourly | data=cleaned\n",
      "Train size=6409, Test size=2219, Removed by cleaning=176\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=daily  | data=orig   \n",
      "Train size=252, Test size=93, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=daily  | data=cleaned\n",
      "Train size=252, Test size=93, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=merge  | data=orig   \n",
      "Train size=6001, Test size=2219, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=merge  | data=cleaned\n",
      "Train size=5840, Test size=2219, Removed by cleaning=161\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "\n",
      "============================================================\n",
      "[GRID] pollutant=NO2(GT)  h=24\n",
      "============================================================\n",
      "FE=hourly | data=orig   \n",
      "Train size=6585, Test size=2207, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=hourly | data=cleaned\n",
      "Train size=6409, Test size=2207, Removed by cleaning=176\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=daily  | data=orig   \n",
      "Train size=252, Test size=92, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=daily  | data=cleaned\n",
      "Train size=252, Test size=92, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=merge  | data=orig   \n",
      "Train size=6001, Test size=2207, Removed by cleaning=0\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "FE=merge  | data=cleaned\n",
      "Train size=5840, Test size=2207, Removed by cleaning=161\n",
      "  Model: LinReg\n",
      "  Model: RF\n",
      "  Model: XGB\n",
      "\n",
      "Regression grid finished.\n",
      "Summary saved to: ../results_reg/summary_full_run_20251119_020758.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pollutant</th>\n",
       "      <th>h</th>\n",
       "      <th>fe_type</th>\n",
       "      <th>data_ver</th>\n",
       "      <th>model</th>\n",
       "      <th>train_n</th>\n",
       "      <th>train_n_eff</th>\n",
       "      <th>clean_removed</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>C6H6(GT)</td>\n",
       "      <td>1</td>\n",
       "      <td>daily</td>\n",
       "      <td>cleaned</td>\n",
       "      <td>LinReg</td>\n",
       "      <td>252.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.545233</td>\n",
       "      <td>2.161793</td>\n",
       "      <td>0.366256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>C6H6(GT)</td>\n",
       "      <td>1</td>\n",
       "      <td>daily</td>\n",
       "      <td>orig</td>\n",
       "      <td>LinReg</td>\n",
       "      <td>252.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.412601</td>\n",
       "      <td>2.038110</td>\n",
       "      <td>0.430584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>C6H6(GT)</td>\n",
       "      <td>1</td>\n",
       "      <td>hourly</td>\n",
       "      <td>cleaned</td>\n",
       "      <td>LinReg</td>\n",
       "      <td>6414.0</td>\n",
       "      <td>6414.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>3.495601</td>\n",
       "      <td>2.532470</td>\n",
       "      <td>0.708231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>C6H6(GT)</td>\n",
       "      <td>1</td>\n",
       "      <td>hourly</td>\n",
       "      <td>orig</td>\n",
       "      <td>LinReg</td>\n",
       "      <td>6590.0</td>\n",
       "      <td>6590.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.832434</td>\n",
       "      <td>2.914623</td>\n",
       "      <td>0.649293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>C6H6(GT)</td>\n",
       "      <td>1</td>\n",
       "      <td>merge</td>\n",
       "      <td>cleaned</td>\n",
       "      <td>LinReg</td>\n",
       "      <td>5845.0</td>\n",
       "      <td>5845.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>3.050386</td>\n",
       "      <td>2.148845</td>\n",
       "      <td>0.777820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pollutant  h fe_type data_ver   model  train_n  train_n_eff  \\\n",
       "97   C6H6(GT)  1   daily  cleaned  LinReg    252.0        252.0   \n",
       "94   C6H6(GT)  1   daily     orig  LinReg    252.0        252.0   \n",
       "91   C6H6(GT)  1  hourly  cleaned  LinReg   6414.0       6414.0   \n",
       "88   C6H6(GT)  1  hourly     orig  LinReg   6590.0       6590.0   \n",
       "103  C6H6(GT)  1   merge  cleaned  LinReg   5845.0       5845.0   \n",
       "\n",
       "     clean_removed      RMSE       MAE        R2  \n",
       "97             0.0  2.545233  2.161793  0.366256  \n",
       "94             0.0  2.412601  2.038110  0.430584  \n",
       "91           176.0  3.495601  2.532470  0.708231  \n",
       "88             0.0  3.832434  2.914623  0.649293  \n",
       "103          161.0  3.050386  2.148845  0.777820  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ================================================================\n",
    "# Cell 3: Run full experiment grid\n",
    "# ================================================================\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"\\n[STEP 1] Running regression experiment grid...\")\n",
    "\n",
    "# ---------------- Naive baseline ----------------\n",
    "def eval_naive_persistence(pollutant: str, h: int):\n",
    "    \"\"\"\n",
    "    Persistence baseline:\n",
    "      y_{t+h} = value of pollutant at t+h\n",
    "      y_hat   = value of pollutant at t\n",
    "    Evaluated on 2005 only.\n",
    "    \"\"\"\n",
    "    if pollutant not in base_df.columns:\n",
    "        raise KeyError(f\"{pollutant} not in base_df\")\n",
    "\n",
    "    y_true_full = make_future_reg_target(base_df, pollutant, h)\n",
    "\n",
    "    y_t = base_df[pollutant]\n",
    "    idx = y_true_full.index.intersection(y_t.index)\n",
    "\n",
    "    y_true = y_true_full.loc[idx]\n",
    "    y_hat  = y_t.loc[idx]\n",
    "\n",
    "    # Test: 2005 only\n",
    "    test_idx = idx[idx.year == 2005]\n",
    "    y_te = y_true.loc[test_idx]\n",
    "    yhat_te = y_hat.loc[test_idx]\n",
    "\n",
    "    metrics = eval_reg_metrics(y_te, yhat_te)\n",
    "    return metrics, y_te, yhat_te\n",
    "\n",
    "\n",
    "# 1) Naive baseline per pollutant × horizon\n",
    "for pollutant in POLLUTANTS:\n",
    "    for h in HORIZONS:\n",
    "        print(f\"\\n[Naive] pollutant={pollutant}, h={h}\")\n",
    "        naive_metrics, y_te_naive, yhat_naive = eval_naive_persistence(pollutant, h)\n",
    "\n",
    "        results.append({\n",
    "            \"pollutant\": pollutant,\n",
    "            \"h\": h,\n",
    "            \"fe_type\": \"N/A\",\n",
    "            \"data_ver\": \"N/A\",\n",
    "            \"model\": \"Naive\",\n",
    "            \"train_n\": np.nan,\n",
    "            \"train_n_eff\": np.nan,\n",
    "            \"clean_removed\": np.nan,\n",
    "            **naive_metrics,\n",
    "        })\n",
    "\n",
    "        if pollutant == \"CO(GT)\" and h in (1, 24):\n",
    "            title_prefix = f\"naive_{pollutant.replace('(GT)','')}_h{h}\"\n",
    "            save_ts_residual_plots(\n",
    "                y_te_naive,\n",
    "                yhat_naive.values,\n",
    "                title_prefix=title_prefix,\n",
    "                out_dir=FIG_DIR,\n",
    "            )\n",
    "\n",
    "\n",
    "model_dict = model_zoo_reg()\n",
    "\n",
    "for pollutant in POLLUTANTS:\n",
    "    for h in HORIZONS:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(f\"[GRID] pollutant={pollutant}  h={h}\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        for fe_type in FE_TYPES:\n",
    "            for data_ver in DATA_VERS:\n",
    "                print(f\"FE={fe_type:6s} | data={data_ver:7s}\")\n",
    "\n",
    "                X_tr, y_tr, X_te, y_te = build_train_test_for_fe(\n",
    "                    fe_type, data_ver, pollutant, h\n",
    "                )\n",
    "                n_train = len(X_tr)\n",
    "\n",
    "                if n_train == 0 or len(X_te) == 0:\n",
    "                    print(\"  Empty train or test set, skipping.\")\n",
    "                    continue\n",
    "\n",
    "                if data_ver == \"orig\":\n",
    "                    clean_removed = 0\n",
    "                else:\n",
    "                    X_tr_orig, _, _, _ = build_train_test_for_fe(\n",
    "                        fe_type, \"orig\", pollutant, h\n",
    "                    )\n",
    "                    clean_removed = max(0, len(X_tr_orig) - len(X_tr))\n",
    "\n",
    "                print(\n",
    "                    f\"Train size={len(X_tr)}, Test size={len(X_te)}, \"\n",
    "                    f\"Removed by cleaning={clean_removed}\"\n",
    "                )\n",
    "\n",
    "                scaler = StandardScaler().fit(X_tr)\n",
    "                X_tr_s = scaler.transform(X_tr)\n",
    "                X_te_s = scaler.transform(X_te)\n",
    "\n",
    "                for m_name, proto in model_dict.items():\n",
    "                    print(f\"  Model: {m_name}\")\n",
    "\n",
    "                    model_cls = proto.__class__\n",
    "                    model = model_cls(**proto.get_params())\n",
    "\n",
    "                    model.fit(X_tr_s, y_tr)\n",
    "                    yhat = model.predict(X_te_s)\n",
    "                    metrics = eval_reg_metrics(y_te, yhat)\n",
    "\n",
    "                    results.append({\n",
    "                        \"pollutant\": pollutant,\n",
    "                        \"h\": h,\n",
    "                        \"fe_type\": fe_type,\n",
    "                        \"data_ver\": data_ver,\n",
    "                        \"model\": m_name,\n",
    "                        \"train_n\": int(n_train),\n",
    "                        \"train_n_eff\": int(len(X_tr)),\n",
    "                        \"clean_removed\": int(clean_removed),\n",
    "                        **metrics,\n",
    "                    })\n",
    "\n",
    "                    if (\n",
    "                        pollutant == \"CO(GT)\"\n",
    "                        and fe_type == \"merge\"\n",
    "                        and data_ver == \"cleaned\"\n",
    "                        and m_name in (\"RF\", \"XGB\", \"GB\", \"LinReg\")\n",
    "                        and h in (1, 24)\n",
    "                    ):\n",
    "                        safe_name = m_name.lower()\n",
    "                        title_prefix = f\"{safe_name}_CO_merge_cleaned_h{h}\"\n",
    "                        save_ts_residual_plots(\n",
    "                            y_te,\n",
    "                            yhat,\n",
    "                            title_prefix=title_prefix,\n",
    "                            out_dir=FIG_DIR,\n",
    "                        )\n",
    "\n",
    "# 3) Save summary table\n",
    "df_res_reg = pd.DataFrame(results)\n",
    "df_res_reg = df_res_reg[\n",
    "    [\n",
    "        \"pollutant\",\n",
    "        \"h\",\n",
    "        \"fe_type\",\n",
    "        \"data_ver\",\n",
    "        \"model\",\n",
    "        \"train_n\",\n",
    "        \"train_n_eff\",\n",
    "        \"clean_removed\",\n",
    "        \"RMSE\",\n",
    "        \"MAE\",\n",
    "        \"R2\",\n",
    "    ]\n",
    "].sort_values([\"pollutant\", \"h\", \"model\", \"fe_type\", \"data_ver\"])\n",
    "\n",
    "summary_path_reg = RESULTS_DIR / f\"summary_full_run_{RUN_TAG}.csv\"\n",
    "df_res_reg.to_csv(summary_path_reg, index=False)\n",
    "\n",
    "print(\"\\nRegression grid finished.\")\n",
    "print(f\"Summary saved to: {summary_path_reg}\")\n",
    "df_res_reg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc1ca92-bbd0-47ab-9bd4-db3def812ba5",
   "metadata": {},
   "source": [
    "### Cell 4 — Analysis by four dimensions (RQ1–RQ4) + plots + CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d30ef54-fcf8-4e9e-b327-91b3390f79a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STEP 2] Post-hoc analysis for regression experiments...\n",
      "\n",
      "[RQ1] Model comparison (cleaned data, FE=merge)...\n",
      "Saved RQ1 summary to: ../results_reg/analysis/rq1_model_comparison_reg.csv\n",
      "\n",
      "[RQ2] Effect of anomaly cleaning (orig vs cleaned)...\n",
      "Saved RQ2 delta table to: ../results_reg/analysis/rq2_anomaly_effect_reg.csv\n",
      "\n",
      "[RQ3] Feature engineering effect (cleaned data only)...\n",
      "Saved RQ3 summary to: ../results_reg/analysis/rq3_fe_effect_reg.csv\n",
      "\n",
      "[RQ4] Horizon effect (average over models, FE, data versions, pollutants)...\n",
      "Saved RQ4 summary to: ../results_reg/analysis/rq4_horizon_effect_reg.csv\n",
      "\n",
      "Regression analysis complete.\n",
      "Full grid results: ../results_reg/summary_full_run_20251119_020758.csv\n",
      "Analysis CSVs   : ../results_reg/analysis\n",
      "Figures         : ../results_reg/figs\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# Cell 4: Post-hoc analysis for RQ1–RQ4 (regression)\n",
    "# ================================================================\n",
    "\n",
    "print(\"\\n[STEP 2] Post-hoc analysis for regression experiments...\")\n",
    "\n",
    "df_all   = df_res_reg.copy()\n",
    "df_naive = df_all[df_all[\"model\"] == \"Naive\"].copy()\n",
    "df_models = df_all[df_all[\"model\"] != \"Naive\"].copy()\n",
    "\n",
    "PRIMARY = \"RMSE\"\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# RQ1: Model family comparison (cleaned, FE=merge)\n",
    "#      averaged over pollutants\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\n[RQ1] Model comparison (cleaned data, FE=merge)...\")\n",
    "\n",
    "rq1 = df_models[\n",
    "    (df_models[\"data_ver\"] == \"cleaned\")\n",
    "    & (df_models[\"fe_type\"] == \"merge\")\n",
    "].copy()\n",
    "\n",
    "rq1_summary = (\n",
    "    rq1.groupby([\"h\", \"model\"])[[\"RMSE\", \"MAE\", \"R2\"]]\n",
    "       .mean()\n",
    "       .reset_index()\n",
    ")\n",
    "\n",
    "rq1_path = ANALYSIS_DIR / \"rq1_model_comparison_reg.csv\"\n",
    "rq1_summary.to_csv(rq1_path, index=False)\n",
    "print(f\"Saved RQ1 summary to: {rq1_path}\")\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "for m in sorted(rq1[\"model\"].unique()):\n",
    "    sub = rq1_summary[rq1_summary[\"model\"] == m]\n",
    "    plt.plot(sub[\"h\"], sub[PRIMARY], marker=\"o\", label=m)\n",
    "\n",
    "plt.xlabel(\"Horizon h (hours)\")\n",
    "plt.ylabel(PRIMARY)\n",
    "plt.title(f\"RQ1 – Model comparison (cleaned, FE=merge, metric={PRIMARY})\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / \"rq1_model_comparison_reg.png\", dpi=220)\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# RQ2: Effect of anomaly cleaning (orig vs cleaned)\n",
    "#       ΔRMSE = cleaned - orig\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\n[RQ2] Effect of anomaly cleaning (orig vs cleaned)...\")\n",
    "\n",
    "def compute_clean_delta_reg(group):\n",
    "    if set(group[\"data_ver\"]) >= {\"orig\", \"cleaned\"}:\n",
    "        m_clean = group[group[\"data_ver\"] == \"cleaned\"][[\"RMSE\", \"MAE\", \"R2\"]].mean()\n",
    "        m_orig  = group[group[\"data_ver\"] == \"orig\"][[\"RMSE\", \"MAE\", \"R2\"]].mean()\n",
    "        return (m_clean - m_orig)\n",
    "    else:\n",
    "        return pd.Series({\"RMSE\": np.nan, \"MAE\": np.nan, \"R2\": np.nan})\n",
    "\n",
    "rq2_delta = (\n",
    "    df_models.groupby([\"pollutant\", \"h\", \"fe_type\", \"model\"])\n",
    "             .apply(compute_clean_delta_reg)\n",
    "             .reset_index()\n",
    ")\n",
    "\n",
    "rq2_path = ANALYSIS_DIR / \"rq2_anomaly_effect_reg.csv\"\n",
    "rq2_delta.to_csv(rq2_path, index=False)\n",
    "print(f\"Saved RQ2 delta table to: {rq2_path}\")\n",
    "\n",
    "rq2_fe_summary = (\n",
    "    rq2_delta.groupby(\"fe_type\")[[\"RMSE\", \"MAE\", \"R2\"]]\n",
    "             .mean()\n",
    "             .reset_index()\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(5, 3.5))\n",
    "plt.bar(rq2_fe_summary[\"fe_type\"], rq2_fe_summary[\"RMSE\"])\n",
    "plt.xlabel(\"FE type\")\n",
    "plt.ylabel(\"Δ RMSE (cleaned - orig)\")\n",
    "plt.title(\"RQ2 – Average cleaning effect by FE type\")\n",
    "plt.grid(axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / \"rq2_cleaning_effect_reg_by_fe.png\", dpi=220)\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# RQ3: Feature engineering effect (cleaned only)\n",
    "#      average over models and pollutants\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\n[RQ3] Feature engineering effect (cleaned data only)...\")\n",
    "\n",
    "rq3 = df_models[df_models[\"data_ver\"] == \"cleaned\"].copy()\n",
    "\n",
    "rq3_summary = (\n",
    "    rq3.groupby([\"h\", \"fe_type\"])[[\"RMSE\", \"MAE\", \"R2\"]]\n",
    "       .mean()\n",
    "       .reset_index()\n",
    ")\n",
    "\n",
    "rq3_path = ANALYSIS_DIR / \"rq3_fe_effect_reg.csv\"\n",
    "rq3_summary.to_csv(rq3_path, index=False)\n",
    "print(f\"Saved RQ3 summary to: {rq3_path}\")\n",
    "\n",
    "pivot = rq3_summary.pivot(index=\"fe_type\", columns=\"h\", values=PRIMARY)\n",
    "\n",
    "plt.figure(figsize=(6, 3.5))\n",
    "im = plt.imshow(pivot.values, aspect=\"auto\", cmap=\"viridis\")\n",
    "plt.colorbar(im, fraction=0.046, pad=0.04, label=PRIMARY)\n",
    "plt.xticks(range(len(pivot.columns)), pivot.columns)\n",
    "plt.yticks(range(len(pivot.index)), pivot.index)\n",
    "plt.xlabel(\"Horizon h (hours)\")\n",
    "plt.ylabel(\"FE type\")\n",
    "plt.title(f\"RQ3 – Feature engineering effect ({PRIMARY})\")\n",
    "\n",
    "for i in range(pivot.shape[0]):\n",
    "    for j in range(pivot.shape[1]):\n",
    "        val = pivot.values[i, j]\n",
    "        plt.text(\n",
    "            j,\n",
    "            i,\n",
    "            f\"{val:.2f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            color=\"white\" if val < pivot.values.max() / 2 else \"black\",\n",
    "            fontsize=8,\n",
    "        )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / \"rq3_fe_effect_reg_heatmap.png\", dpi=220)\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# RQ4: Horizon effect (average over models / FE / versions / pollutants)\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\n[RQ4] Horizon effect (average over models, FE, data versions, pollutants)...\")\n",
    "\n",
    "rq4_summary = (\n",
    "    df_models.groupby(\"h\")[[\"RMSE\", \"MAE\", \"R2\"]]\n",
    "             .mean()\n",
    "             .reset_index()\n",
    ")\n",
    "\n",
    "rq4_path = ANALYSIS_DIR / \"rq4_horizon_effect_reg.csv\"\n",
    "rq4_summary.to_csv(rq4_path, index=False)\n",
    "print(f\"Saved RQ4 summary to: {rq4_path}\")\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(rq4_summary[\"h\"], rq4_summary[\"RMSE\"], marker=\"o\", label=\"RMSE\")\n",
    "plt.plot(rq4_summary[\"h\"], rq4_summary[\"MAE\"], marker=\"o\", label=\"MAE\")\n",
    "plt.xlabel(\"Horizon h (hours)\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.title(\"RQ4 – Average regression error vs horizon\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / \"rq4_reg_error_vs_horizon.png\", dpi=220)\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nRegression analysis complete.\")\n",
    "print(f\"Full grid results: {summary_path_reg}\")\n",
    "print(f\"Analysis CSVs   : {ANALYSIS_DIR}\")\n",
    "print(f\"Figures         : {FIG_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e33bf0a-e3ff-4d75-b68e-55f7e82a4554",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
